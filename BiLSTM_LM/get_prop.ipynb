{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model import BiLSTM\n",
    "from utils import sentences_to_indices, w2i, i2w\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = '怀[mask]是一种错觉'\n",
    "model = torch.load(\"./model/LM_128_withsoftmaxbn.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['怀', '[mask]', '是', '一', '种', '错', '觉'], 0)\n"
     ]
    }
   ],
   "source": [
    "#调整[mask]\n",
    "def de_mask(input_sentence):\n",
    "    flag = 0\n",
    "    input = list(input_sentence)\n",
    "    for i in range(len(input)):\n",
    "        if i + 2 <= len(input) and input[i] == '[' and input[i + 1] == 'm' and input[i + 2] == 'a':\n",
    "            input[i] = '[mask]'\n",
    "            flag = i - 1#预测的位置\n",
    "            del input[i+1:i + 6]\n",
    "    return input, flag\n",
    "print(de_mask(input_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(input_sentence, flag):\n",
    "    '''\n",
    "\n",
    "    :param input_sentence:\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    input_indices_orig, _ = sentences_to_indices(input_sentence, w2i)\n",
    "\n",
    "    L = len(input_indices_orig)\n",
    "    input_orig = torch.zeros([1, L], dtype=torch.int64).to(device)\n",
    "    input = torch.zeros_like(input_orig)\n",
    "    for i in range(L):\n",
    "        input_orig[0][i] = input_indices_orig[i]\n",
    "\n",
    "    out1 = softmax(model(input_orig), dim=1)\n",
    "    max_indices = int(torch.argmax(out1[flag]).cpu().detach().numpy())\n",
    "    input_sentence[flag+1] = i2w[max_indices]\n",
    "    input_indices, _ = sentences_to_indices(input_sentence, w2i)\n",
    "\n",
    "    for i in range(L):\n",
    "        input[0][i] = input_indices[i]\n",
    "\n",
    "    out = softmax(model(input), dim=1)\n",
    "\n",
    "    indices = list(torch.argsort(out[flag], descending=True)[0:5].cpu().detach().numpy())\n",
    "\n",
    "    for idx in range(len(indices)):\n",
    "        key = indices[idx]\n",
    "        word = i2w[key]\n",
    "        prob = out[flag][key].cpu().detach().numpy()\n",
    "        print(prob, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53801274 旧\n",
      "0.42279974 法\n",
      "0.016204016 制\n",
      "0.007340036 从\n",
      "0.004868505 者\n"
     ]
    }
   ],
   "source": [
    "s, flag = de_mask(input_sentence)\n",
    "get_prob(s, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
